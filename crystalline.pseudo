struct Node { // Each node takes 3 memory words
    union {
        uint64 refc; // REFS: Refcounter
        Node∗ bnext; // SLOT: Next node
    };
    union { // SLOT nodes reuse space after retire
        uint64 birth; // Node's birth era
        Reservation∗ slot; // Used in Crystalline
        Node∗ next; // SLOT: After retire
    };
    Node∗ blink; // REFS: First SLOT node,
}; // SLOT: Pointer to REFS
struct Batch { // Accumulates nodes before retiring
    Node∗ first, refs; // Init: nullptr, nullptr
    int counter; // Init: 0
};
thread_local Batch batch; // Per−thread batches

uint64 global_era = 1;
thread_local int alloc_cnt = 0;

struct Reservation { // Add the 'era' field
    Node∗ list; // Init: invptr
    uint64 era; // Init: 0
};
Reservation rsrv[MAX_THREADS][MAX_IDX];

void traverse(Node∗ next) {
    while (next != nullptr) {
        Node∗ curr = next;
        next = SWAP(&curr− > next, invptr); // Tainting
        Node∗ refs = curr− > blink;
        if (FAA(&refs− > refc, −1) == 1)
            free_batch(refs);
    }
}

void free_batch(Node∗ refs) { // RNODE is used later for
    // Cryst−W, dummy (n=refs−>blink) for Hyaline/Cryst−L
    Node∗ n = RNODE(refs− > blink);
    do {
        Node∗ obj = n;
        // refc & bnext overlap and are 0
        // (nullptr) for the last REFS node
        n = n− > bnext;
        free(obj);
    } while (n != nullptr);
}

void clear() {
    for (int i = 0; i < MAX_IDX; i++) {
        Node∗ p = SWAP(&rsrv[TID][i].list, invptr);
        if (p != invptr)
            traverse(p);
    }
}

void try_retire() { // A wait−free replacement
    uint64 min_birth = batch.refs− > birth;
    Node∗ last = batch.first;
    // Check if the number of nodes suffices
    for (int i = 0; i < MAX_THREADS; i++) {
        for (int j = 0; j < MAX_IDX; j++) {
            if (rsrv[i][j].list == invptr)
                continue;
            if (rsrv[i][j].era < min_birth)
                continue;
            if (last == batch.refs)
                return; // Ran out of nodes, exit
            last− > slot = &rsrv[i][j];
            last = last− > bnext;
        }
    }
    Node∗ curr = batch.first; // Make the loop wait−
    int64 cnt = −REFC_PROTECT; // free by tainting
    for (; curr != last; curr = curr− > bnext) {
        Reservation∗ slot = curr− > slot;
        if (slot− > list == invptr)
            continue;
        curr− > next = nullptr;
        Node∗ prev = SWAP(&slot− > list, curr);
        if (prev != nullptr) {
            if (prev == invptr) { // Inactive previously
                if (CAS(&slot− > list, curr, invptr))
                    continue; // Try to rollback
            } else { // Tainted: traverse a chopped tail
                if (!CAS(&curr− > next, nullptr, prev))
                    traverse(prev);
            }
        }
        cnt++;
    }
    if (FAA(&batch.refs− > refc, cnt) == −cnt)
        free_batch(batch.refs);
    batch.first = nullptr;
    batch.counter = 0;
}

// Clean up the old list and set a new era
uint64 update_era(uint64 curr_era, int index) {
    if (rsrv[TID][index].list != nullptr) {
        Node∗ list = SWAP(&rsrv[TID][index].list, nullptr);
        if (list != invptr)
            traverse(list);
        curr_era = global_era;
    }
    rsrv[TID][index].era = curr_era;
    return curr_era;
}

void retire(Node∗ node) {
    if (!batch.first) { // the REFS node
        batch.refs = node;
        node− > refc = REFC_PROTECT;
    } else { // SLOT nodes
        // Reuse the birth era of REFS to retain
        // the minimum birth era in the batch
        if (batch.refs− > birth > node− > birth)
            batch.refs− > birth = node− > birth;
        node− > blink = batch.refs; // points to REFS
        node− > bnext = batch.first;
    }
    batch.first = node;
    if (batch.counter++ % RETIRE_FREQ == 0) {
        // blink of REFS points to the 1st SLOT node
        batch.refs− > blink = RNODE(batch.first);
        try_retire();
    }
}
